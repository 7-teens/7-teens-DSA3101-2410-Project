{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief Report: Implementation of AI Chatbot Using LLM for Personalized Customer Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "This report delves into the comprehensive implementation of an AI chatbot powered by a large language model (LLM) to manage customer queries and deliver personalized product recommendations within an e-commerce platform. It aims to assess the chatbot’s capacity for enhancing customer engagement and experience while evaluating its effectiveness in improving customer satisfaction and support efficiency. The potential advantages of using LLMs for personalized customer interactions, alongside the challenges encountered during the chatbot's development, are also explored. Finally, ethical considerations regarding privacy and fairness in AI systems are discussed.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Implementation\n",
    "\n",
    "### 2.1 Data Preparation and Integration\n",
    "The chatbot operates by leveraging three primary datasets:\n",
    "- **Customers Dataset**: This dataset includes key information such as customer IDs, login history, and checkout activity. The chatbot uses this data to track each customer's interaction with the platform and personalize its responses accordingly. \n",
    "- **Orders Dataset**: This dataset records transactional details like order IDs, product IDs, timestamps, and order statuses. It enables the chatbot to respond to customer inquiries regarding their past or current orders, including status updates.\n",
    "- **Products Dataset**: This contains vital product information, such as names, prices, and customer ratings. The chatbot uses this dataset to provide detailed product information and make personalized recommendations based on user behavior.\n",
    "\n",
    "Seamless integration of these datasets is essential to ensure that the chatbot can deliver personalized, real-time responses. Consistent formatting and data type conversions across datasets allow for efficient querying and minimize the risk of data discrepancies.\n",
    "\n",
    "### 2.2 LLM-Based Natural Language Processing (NLP)\n",
    "The chatbot leverages **DialoGPT**, a pre-trained LLM designed for conversational tasks. This model enables the chatbot to interpret and generate human-like responses to user inputs. Using the LLM, the chatbot can handle diverse queries, including product inquiries, order tracking, and personalized recommendations. DialoGPT's flexibility allows it to generate coherent and contextually appropriate replies to a broad array of customer questions, reducing the need for rule-based systems.\n",
    "\n",
    "The key advantage of using an LLM is its ability to generalize across different types of queries, making it highly adaptable to various conversational patterns. This eliminates the need to manually program responses for every potential user input, streamlining chatbot development and improving its ability to handle unstructured or unexpected questions.\n",
    "\n",
    "### 2.3 Context Management and Memory\n",
    "A core feature of the chatbot is its ability to retain and manage context across multiple user interactions. This feature ensures that the chatbot can recall previous queries and maintain a coherent conversation with the user, providing a seamless experience. For example, if a customer asks about a product and then follows up with a request for its price, the chatbot remembers the product from the previous query and provides the correct information without requiring the customer to repeat themselves.\n",
    "\n",
    "This contextual memory is implemented through a dictionary that stores the user’s last product inquiry, intent (e.g., price or rating request), and order information. This significantly improves the efficiency and fluidity of conversations, particularly when handling multi-part queries.\n",
    "\n",
    "### 2.4 Core Functionalities\n",
    "The chatbot is designed to address the most common customer needs within the e-commerce platform. Its key functionalities include:\n",
    "- **Customer Information Retrieval**: The chatbot can access and relay customer-specific information, such as login history and past checkout details, allowing it to provide personalized insights based on the customer's prior behavior.\n",
    "- **Product Recommendations**: It suggests products based on a customer's previous purchases. If no purchase history is available, the chatbot recommends popular products, enhancing the user experience with relevant suggestions.\n",
    "- **Order Status Tracking**: Customers can request updates on their orders by providing the order ID, and the chatbot will retrieve and display the relevant details.\n",
    "- **Product Information Queries**: Customers can ask about product prices or ratings, and the chatbot will query the product dataset to provide accurate, real-time responses.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Implementation Details and Architecture of the LLM-Based System\n",
    "\n",
    "The LLM-based chatbot system is designed to handle customer queries, provide product recommendations, and manage interactions within an e-commerce platform. The architecture integrates a large language model (LLM), data handling components, and context management mechanisms to deliver a fluid and responsive customer support experience. Below are the implementation details and the architecture of the system.\n",
    "\n",
    "### 1. **LLM Integration (DialoGPT)**\n",
    "\n",
    "The core of the chatbot's conversational ability is powered by **DialoGPT**, a transformer-based language model optimized for dialogue. This pre-trained model is fine-tuned to generate human-like responses based on the context provided by the user input.\n",
    "\n",
    "- **Model Selection**: The system uses **microsoft/DialoGPT-medium** due to its balance of response quality and computational efficiency.\n",
    "- **Tokenization and Encoding**: User input is processed using a tokenizer that prepares the input text for the model. The input is tokenized into a format that the model can understand, allowing for efficient text generation.\n",
    "- **Response Generation**: The chatbot generates responses by sampling from the model's learned distribution of dialogue possibilities. Parameters like **top-k** and **top-p** control the diversity of responses, ensuring that the chatbot produces coherent yet varied answers.\n",
    "\n",
    "```python\n",
    "# Loading the DialoGPT model and tokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"microsoft/DialoGPT-medium\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "```\n",
    "\n",
    "### 2. **Data Handling and Integration**\n",
    "\n",
    "The chatbot interacts with three primary datasets:\n",
    "- **Customers Dataset**: Stores information about customers, including customer IDs, last login dates, and checkout history. This data allows the chatbot to personalize responses and make recommendations based on user behavior.\n",
    "- **Orders Dataset**: Contains order-related information such as order IDs, product IDs, and timestamps. This dataset is used to provide customers with real-time updates on the status of their orders.\n",
    "- **Products Dataset**: Holds details about the products available in the e-commerce platform, including product names, prices, descriptions, and customer ratings. The chatbot retrieves information from this dataset to answer product-related queries and suggest items to customers.\n",
    "\n",
    "Data integration is essential for ensuring that the chatbot can access and manipulate these datasets in real-time, providing up-to-date and accurate responses to customer queries.\n",
    "\n",
    "```python\n",
    "# Load datasets\n",
    "customers_df = pd.read_csv(\"../Cleaned_Datasets/customer_SG_only.csv\", index_col=0)  # customer data\n",
    "orders_df = pd.read_csv(\"../Cleaned_Datasets/orders_generated.csv\", index_col=0)  # order data\n",
    "products_df = pd.read_csv(\"../Cleaned_Datasets/products_cleaned.csv\", index_col=0)  # product data\n",
    "\n",
    "# Convert customer_id columns to strings in both DataFrames\n",
    "customers_df['customer_id'] = customers_df['customer_id'].astype(str)\n",
    "orders_df['customer_id'] = orders_df['customer_id'].astype(str)\n",
    "```\n",
    "\n",
    "### 3. **Context Management**\n",
    "- The chatbot maintains context between queries, allowing it to engage in more natural, multi-turn conversations. For example, if a customer asks about a product and later asks about its price, the chatbot remembers the product in question.\n",
    "- Context Storage: A dictionary is used to store details such as the last product mentioned, last customer ID, and last order ID. This information is updated with each interaction to maintain the flow of the conversation.\n",
    "\n",
    "```python\n",
    "# Context management for follow-up queries\n",
    "context = {\n",
    "    \"last_product\": None,  # Stores the last product mentioned\n",
    "    \"last_intent\": None,   # Stores the last intent (price, rating, etc.)\n",
    "    \"last_customer\": None, # Stores last customer ID\n",
    "    \"last_order\": None     # Stores last order ID\n",
    "}\n",
    "```\n",
    "\n",
    "### 4. **Intent Detection and Query Handling**\n",
    "- The chatbot uses regular expressions (regex) to detect user intent (e.g., asking for order status or product price). Based on the detected intent, the chatbot queries the relevant dataset and retrieves the information requested by the customer.\n",
    "- Response Handling: After determining the user's intent (e.g., asking for product recommendations), the chatbot generates responses by combining the output from datasets and the LLM.\n",
    "\n",
    "```python\n",
    "# Regex-based intent detection\n",
    "def detect_intent_and_entities(user_input):\n",
    "    # Prioritize recommendation detection over customer queries\n",
    "    if \"recommend\" in user_input.lower() and \"customer\" in user_input.lower():\n",
    "        customer_id = re.search(r'\\d+', user_input).group(0)\n",
    "        return \"recommendation\", {\"customer_id\": customer_id}\n",
    "\n",
    "    # Regex patterns to detect customer query intent\n",
    "    if re.search(r'customer.*id.*\\d+', user_input, re.IGNORECASE):\n",
    "        intent = \"customer_query\"\n",
    "        customer_id = re.search(r'\\d+', user_input).group(0)\n",
    "        return intent, {\"customer_id\": customer_id}\n",
    "    \n",
    "    # Regex patterns to detect order query intent\n",
    "    if re.search(r'order.*id', user_input, re.IGNORECASE):\n",
    "        intent = \"order_query\"\n",
    "        order_id = re.search(r'order_[0-9]+', user_input, re.IGNORECASE)\n",
    "        return intent, {\"order_id\": order_id.group(0)} if order_id else {\"order_id\": None}\n",
    "    \n",
    "    # Regex patterns to detect product price or rating queries\n",
    "    if re.search(r'price|rating', user_input, re.IGNORECASE):\n",
    "        product_name_match = re.search(r'(?:price|rating) of (.+)', user_input, re.IGNORECASE)\n",
    "        product_name = product_name_match.group(1).strip() if product_name_match else None\n",
    "        intent = \"product_price\" if \"price\" in user_input.lower() else \"product_rating\"\n",
    "        return intent, {\"product_name\": product_name}\n",
    "\n",
    "    # Fallback for general queries\n",
    "    return \"general\", {}\n",
    "```\n",
    "\n",
    "### 5. **LLM Response Generation**\n",
    "- If no specific intent is detected, the chatbot falls back to LLM-based conversation using DialoGPT, which generates a free-form conversational response based on user input and the dialogue history.\n",
    "\n",
    "```python\n",
    "# LLM (DialoGPT) Chat Handling\n",
    "def chat_with_dialoGPT(user_input, chat_history_ids=None):\n",
    "    new_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt')\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_input_ids], dim=-1) if chat_history_ids is not None else new_input_ids\n",
    "    attention_mask = torch.ones(bot_input_ids.shape, dtype=torch.long)\n",
    "    \n",
    "    chat_history_ids = model.generate(\n",
    "        bot_input_ids,\n",
    "        max_length=1000,\n",
    "        attention_mask=attention_mask,\n",
    "        do_sample=True,\n",
    "        top_p=0.92,\n",
    "        top_k=50,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "    return response, chat_history_ids\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Potential of LLMs for Personalized Customer Support and Engagement\n",
    "\n",
    "### 4.1 Enhanced Customer Experience\n",
    "LLMs are highly effective at simulating natural, conversational interactions, allowing the chatbot to engage customers in a more human-like and engaging manner. This greatly enhances the overall customer experience, as users feel they are interacting with an intelligent agent that understands their needs. The ability of LLMs to understand and process complex queries, while maintaining conversation flow, reduces the need for users to adapt their communication style to the chatbot, resulting in a smoother and more intuitive experience.\n",
    "\n",
    "Moreover, the chatbot’s ability to retain context across queries ensures that customers do not have to repeat themselves. For example, after asking for a product recommendation, users can inquire about the price or rating of one of the recommended items without having to restate which product they are referring to. This increases user satisfaction and reduces frustration, especially in multi-step inquiries.\n",
    "\n",
    "### 4.2 Scalability and Flexibility\n",
    "One of the major advantages of using LLMs in a chatbot is their scalability. Unlike traditional rule-based systems, which require manual updates for each new use case or product offering, LLMs can generalize across a wide range of conversational patterns. This allows the chatbot to handle an evolving product catalog, changing customer preferences, and varied customer interactions without constant reprogramming.\n",
    "\n",
    "As the e-commerce platform grows, so do the demands on customer support. An LLM-powered chatbot can handle a high volume of queries simultaneously, providing real-time responses even during peak shopping periods. This makes it a cost-effective and scalable solution for large e-commerce platforms, where human customer service agents would struggle to keep up with demand.\n",
    "\n",
    "### 4.3 Data-Driven Personalization\n",
    "LLMs enable highly personalized interactions by integrating customer data into responses. By analyzing purchase history, browsing patterns, and other behavioral data, the chatbot can tailor recommendations and responses to each customer’s preferences. For example, if a user frequently purchases sports equipment, the chatbot can suggest related items or highlight sales in that category. This level of personalization drives engagement and encourages repeat purchases, as customers feel that the platform understands their needs.\n",
    "\n",
    "Beyond recommendations, LLMs can predict future customer behavior by analyzing patterns in past interactions. This predictive capability can be used to proactively suggest products or services that align with the customer’s evolving interests, further enhancing the platform's ability to engage users effectively.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation of Effectiveness: Customer Satisfaction and Support Efficiency\n",
    "\n",
    "### 5.1 Customer Satisfaction\n",
    "The chatbot’s effectiveness is measured through metrics such as **response time** and **customer feedback**. Quick, accurate responses are crucial to maintaining high levels of customer satisfaction. The chatbot’s ability to provide immediate answers to queries, such as product prices or order statuses, helps reduce customer wait times, resulting in a more satisfying user experience.\n",
    "\n",
    "Furthermore, the chatbot actively solicits feedback from customers at the end of each session, allowing the platform to assess user satisfaction and identify areas for improvement. This feedback is crucial for continuously refining the chatbot’s responses and ensuring that it meets customer expectations.\n",
    "\n",
    "```python\n",
    "# Function to collect customer feedback after the session\n",
    "def request_feedback():\n",
    "    feedback = input(\"Bot: How would you rate your experience on a scale from 1 to 5? \")\n",
    "    if feedback.isdigit() and 1 <= int(feedback) <= 5:\n",
    "        return int(feedback)\n",
    "    return None\n",
    "```\n",
    "\n",
    "### 5.2 Support Efficiency\n",
    "By automating routine tasks such as answering product inquiries and tracking orders, the chatbot significantly reduces the workload on human support staff. This allows human agents to focus on more complex or high-value interactions, improving the overall efficiency of the customer support team. The chatbot is capable of handling thousands of interactions simultaneously, which is particularly beneficial during busy periods like sales events or holiday seasons.\n",
    "\n",
    "The chatbot’s ability to scale efficiently makes it an invaluable asset for the platform. It can address a wide range of customer concerns without requiring additional staffing, thereby lowering operational costs while maintaining high-quality customer service.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Integration of FastAPI for Enhanced Chatbot Functionality\n",
    "\n",
    "The integration of FastAPI has transformed the chatbot into a comprehensive, efficient, and scalable solution. This integration leverages asynchronous processing to enhance performance, handling diverse user queries, such as retrieving customer details, order status, and product recommendations. Additionally, it incorporates feedback collection and metrics tracking for ongoing evaluation and improvement.\n",
    "\n",
    "### **1. FastAPI Framework Setup**\n",
    "\n",
    "FastAPI was chosen for its high performance and ability to handle asynchronous requests, making it ideal for a chatbot requiring rapid and concurrent responses. The FastAPI application is initialized as follows:\n",
    "\n",
    "- Import necessary FastAPI libraries and initialize an app instance.\n",
    "\n",
    "```python\n",
    "    from fastapi import FastAPI\n",
    "    from pydantic import BaseModel\n",
    "\n",
    "    app = FastAPI()\n",
    "```\n",
    "\n",
    "This instance serves as the main interface for handling user interactions through various API endpoints.\n",
    "\n",
    "### **2. Loading and Preprocessing Data**\n",
    "\n",
    "To support data-driven interactions, customer, order, and product data are loaded from CSV files. These files are read into pandas DataFrames for efficient querying and manipulation.\n",
    "\n",
    "- Load datasets from CSV files, and ensure 'customer_id' columns are of string type to avoid mismatches.\n",
    "\n",
    "```python\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    customers_df = pd.read_csv(os.path.join(base_dir, \"../Cleaned_Datasets/customer_SG_only.csv\"), index_col=0)\n",
    "    orders_df = pd.read_csv(os.path.join(base_dir, \"../Cleaned_Datasets/orders_generated.csv\"), index_col=0)\n",
    "    products_df = pd.read_csv(os.path.join(base_dir, \"../Cleaned_Datasets/products_cleaned.csv\"), index_col=0)\n",
    "\n",
    "    customers_df['customer_id'] = customers_df['customer_id'].astype(str)\n",
    "    orders_df['customer_id'] = orders_df['customer_id'].astype(str)\n",
    "```\n",
    "\n",
    "These DataFrames allow the chatbot to seamlessly access and filter data based on user queries.\n",
    "\n",
    "### **3. Chatbot and General Conversation with DialoGPT**\n",
    "\n",
    "To handle general conversational interactions, the chatbot uses the pre-trained DialoGPT model. The asynchronous nature of FastAPI enhances response time and allows for context-driven dialogue.\n",
    "\n",
    "- Load the DialoGPT model and define the function to generate conversational responses.\n",
    "\n",
    "```python\n",
    "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "    import torch\n",
    "\n",
    "    model_name = \"microsoft/DialoGPT-medium\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    def chat_with_dialoGPT(user_input, chat_history_ids=None):\n",
    "        new_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt')\n",
    "        bot_input_ids = torch.cat([torch.tensor(chat_history_ids), new_input_ids], dim=-1) if chat_history_ids else new_input_ids\n",
    "        \n",
    "        chat_history_ids = model.generate(\n",
    "            bot_input_ids, max_length=1000, do_sample=True, top_p=0.92, top_k=50, pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "        return response, chat_history_ids.tolist()\n",
    "```\n",
    "\n",
    "This function generates a conversational response, using DialoGPT to maintain a friendly and interactive dialogue with the user.\n",
    "\n",
    "### **4. Core API Endpoints**\n",
    "\n",
    "The API structure includes various endpoints to handle specific user requests, such as retrieving customer details, checking order statuses, and providing product recommendations.\n",
    "\n",
    "#### Chat Endpoint (/chat/)\n",
    "\n",
    "- The `/chat/` endpoint processes user inputs, detects intent, and generates responses tailored to the identified intent. It routes requests to the appropriate handler function based on intent (e.g., retrieving customer info, checking order status).\n",
    "\n",
    "```python\n",
    "    from fastapi import Request\n",
    "\n",
    "    class ChatRequest(BaseModel):\n",
    "        user_input: str\n",
    "        chat_history_ids: list = None\n",
    "\n",
    "    @app.post(\"/chat/\")\n",
    "    async def chat_with_bot(request: ChatRequest):\n",
    "        user_input = request.user_input\n",
    "        chat_history_ids = request.chat_history_ids or None\n",
    "\n",
    "        intent, entities = detect_intent_and_entities(user_input)\n",
    "        \n",
    "        if intent == \"customer_query\":\n",
    "            response = get_customer_info(entities[\"customer_id\"])\n",
    "        elif intent == \"order_query\":\n",
    "            response = get_order_status(entities[\"order_id\"])\n",
    "        elif intent in [\"product_price\", \"product_rating\"]:\n",
    "            product_name = entities.get(\"product_name\")\n",
    "            response = get_product_info(product_name, info_type=intent.split(\"_\")[1])\n",
    "        elif intent == \"recommendation\":\n",
    "            response = recommend_products(entities[\"customer_id\"])\n",
    "        else:\n",
    "            response, chat_history_ids = chat_with_dialoGPT(user_input, chat_history_ids)\n",
    "\n",
    "        return {\"response\": response, \"chat_history_ids\": chat_history_ids if intent == \"general\" else None}\n",
    "```\n",
    "\n",
    "This endpoint allows the chatbot to dynamically determine the type of query and respond accordingly, whether by accessing customer information, checking an order, or recommending products.\n",
    "\n",
    "#### Feedback Endpoint (/feedback/)\n",
    "\n",
    "- The `/feedback/` endpoint captures user feedback after interactions, enabling ongoing assessment of user satisfaction.\n",
    "\n",
    "```python\n",
    "    class FeedbackRequest(BaseModel):\n",
    "        rating: int\n",
    "\n",
    "    @app.post(\"/feedback/\")\n",
    "    async def collect_feedback(feedback: FeedbackRequest):\n",
    "        if not (1 <= feedback.rating <= 5):\n",
    "            raise HTTPException(status_code=400, detail=\"Rating must be between 1 and 5.\")\n",
    "        feedback_scores.append(feedback.rating)\n",
    "        return {\"message\": f\"Thank you for your feedback! You rated this session {feedback.rating}/5.\"}\n",
    "```\n",
    "\n",
    "This endpoint validates the rating (1 to 5) and stores it in a list for performance analysis.\n",
    "\n",
    "#### Metrics Endpoint (/metrics/)\n",
    "\n",
    "- The `/metrics/` endpoint provides an overview of the chatbot’s performance, including metrics such as average response time and feedback score, which help in identifying areas for improvement.\n",
    "\n",
    "```python\n",
    "    @app.get(\"/metrics/\")\n",
    "    async def get_metrics():\n",
    "        avg_response_time = sum(response_times) / len(response_times) if response_times else 0\n",
    "        avg_feedback_score = sum(feedback_scores) / len(feedback_scores) if feedback_scores else 0\n",
    "        \n",
    "        return {\n",
    "            \"average_response_time\": avg_response_time,\n",
    "            \"average_feedback_score\": avg_feedback_score,\n",
    "            \"total_feedback_count\": len(feedback_scores)\n",
    "        }\n",
    "```\n",
    "\n",
    "This endpoint aggregates and returns metrics data, which is essential for monitoring chatbot efficacy and user satisfaction.\n",
    "\n",
    "### **5. Example API Interaction Workflow**\n",
    "\n",
    "To illustrate the chatbot’s capabilities, here’s an example interaction workflow using the FastAPI integration:\n",
    "\n",
    "**Example Workflow**: The user requests the \"price of Apple Pencil.\"\n",
    "\n",
    "1. **User Interaction**: The user inputs, \"What is the price of Apple Pencil?\"\n",
    "2. **Intent Detection**: The `/chat/` endpoint detects a \"product_price\" intent and identifies \"Apple Pencil\" as the product.\n",
    "3. **Data Querying**: The `get_product_info` function is called, querying the product dataset for the price of \"Apple Pencil.\"\n",
    "4. **Response Generation**: The bot responds with, \"The Apple Pencil is priced at $99,\" or another relevant price based on the data.\n",
    "5. **Feedback Collection**: If the user provides feedback on the interaction via the `/feedback/` endpoint, it is recorded for further analysis.\n",
    "\n",
    "### **6. Using the API**\n",
    "\n",
    "Here is a step-by-step guide on how to start and use the API.\n",
    "\n",
    "#### <u>Step 1: Start the API Server</u>\n",
    "\n",
    "- **Open a Terminal**: Open your terminal or command prompt.\n",
    "- **Navigate to Your Project Directory**: Change the directory to where your FastAPI code is located.\n",
    "    \n",
    "    cd /path/to/your/project/directory\n",
    "    \n",
    "- **Run the Uvicorn Server**: Start the server using the following command:\n",
    "\n",
    "    uvicorn Chatbot.chatbot_api:app --reload --port 8001\n",
    "\n",
    "  Here, `Chatbot.chatbot_api:app` refers to the file and app instance where your FastAPI code is located. Adjust this if your file structure or app name is different.\n",
    "  \n",
    "  - The `--reload` option enables hot reloading, which reloads the server if you make code changes.\n",
    "  - The `--port 8001` specifies the port; adjust if needed, but ensure that it matches in the URL.\n",
    "\n",
    "- **Verify the Server is Running**: After running the command, you should see output in the terminal indicating that Uvicorn is running on `http://127.0.0.1:8001`. You’ll see something like:\n",
    "\n",
    "    Uvicorn running on http://127.0.0.1:8001 (Press CTRL+C to quit)\n",
    "\n",
    "#### <u>Step 2: Access the API Documentation</u>\n",
    "\n",
    "- **Open the Swagger UI**: In your web browser, go to `http://127.0.0.1:8001/docs`.\n",
    "- This is the interactive API documentation automatically generated by FastAPI using Swagger UI.\n",
    "\n",
    "#### <u>Step 3: Test the Endpoints</u>\n",
    "\n",
    "In the Swagger UI, you’ll see the available endpoints (`/chat/`, `/feedback/`, `/metrics/`, etc.). Here’s how to use each one:\n",
    "\n",
    "- **A. Testing the `/chat/` Endpoint**\n",
    "  - Locate the `/chat/` Endpoint: Scroll down to find the `POST /chat/` endpoint.\n",
    "  - Click **Try it out** to enable input fields.\n",
    "  - Enter Input Parameters:\n",
    "    - `user_input`: Enter the text you want to send to the chatbot, such as \"What's the price of Apple Pencil?\".\n",
    "    - `chat_history_ids`: Leave this empty for the first question, as it is used for tracking chat context.\n",
    "  - Click **Execute** to send the request to the API.\n",
    "  - View the Response: Check the \"Response body\" section to see the chatbot’s response. You’ll see fields like \"response\" and \"chat_history_ids\".\n",
    "  - For follow-up questions, copy `chat_history_ids` from the response and use it as input for the next request to maintain the conversation context.\n",
    "\n",
    "- **B. Testing the `/feedback/` Endpoint**\n",
    "  - Locate the `/feedback/` Endpoint: Find `POST /feedback/`.\n",
    "  - Click **Try it out**.\n",
    "  - Enter Feedback:\n",
    "    - `rating`: Enter a rating from 1 to 5 to provide feedback on the chatbot session.\n",
    "  - Click **Execute**.\n",
    "  - View the Response: You should see a confirmation message like \"Thank you for your feedback! You rated this session 5/5.\".\n",
    "\n",
    "- **C. Testing the `/metrics/` Endpoint**\n",
    "  - Locate the `/metrics/` Endpoint: Find `GET /metrics/`.\n",
    "  - Click **Try it out**.\n",
    "  - Click **Execute**.\n",
    "  - View the Metrics: In the response, you should see data like `average_response_time`, `average_feedback_score`, and `total_feedback_count`.\n",
    "    - `average_response_time` will show the average time taken to process chat responses.\n",
    "    - `average_feedback_score` will reflect the average of all feedback ratings.\n",
    "    - `total_feedback_count` will display the number of feedback submissions.\n",
    "\n",
    "#### <u>Step 4: Stop the Server</u>\n",
    "\n",
    "When you’re done testing, go back to the terminal and press **CTRL+C** to stop the Uvicorn server.\n",
    "\n",
    "### **7. Benefits of FastAPI Integration**\n",
    "\n",
    "Integrating FastAPI has brought significant improvements to the chatbot system. Here’s a detailed breakdown of the advantages:\n",
    "\n",
    "1. **Modularity and Maintainability**: FastAPI's endpoint structure enables a modular approach, where each functionality (e.g., chat, feedback, metrics) is encapsulated in separate endpoints. This improves maintainability by isolating each function, making it easier to update or modify without affecting the overall system.\n",
    "\n",
    "2. **Enhanced Performance with Asynchronous Processing**: FastAPI natively supports asynchronous processing, which is critical for handling concurrent user requests in real-time. This allows the chatbot to efficiently manage multiple interactions simultaneously, reducing wait times and enhancing user experience.\n",
    "\n",
    "3. **Real-Time Feedback and Continuous Improvement**: The feedback mechanism enables real-time collection of user ratings, providing a direct measure of user satisfaction. This feedback loop allows the chatbot to be iteratively improved based on user responses, helping to identify and address potential pain points.\n",
    "\n",
    "4. **Scalability for Future Expansion**: With FastAPI’s flexibility, additional features can be easily added as new endpoints. For instance, new endpoints for handling returns or tracking loyalty points could be integrated without disrupting existing functionalities, allowing for future expansion of the chatbot's capabilities.\n",
    "\n",
    "5. **Data-Driven Interactions with Context Awareness**: The chatbot’s context-tracking system retains information on recent interactions (e.g., last queried product or customer). This enables the bot to provide more relevant and contextually aware responses, contributing to a more personalized user experience.\n",
    "\n",
    "6. **Detailed Analytics and Monitoring**: The `/metrics/` endpoint allows real-time monitoring of response times and average feedback scores, providing insights into the chatbot’s performance. This data supports data-driven decisions to optimize the bot’s responsiveness and accuracy over time.\n",
    "\n",
    "In summary, the integration of FastAPI transforms the chatbot into a robust, scalable, and efficient tool capable of managing complex interactions and delivering a high-quality user experience. The API-based architecture enhances modularity, maintainability, and scalability, laying a solid foundation for future improvements and expansions.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Potential Benefits for the E-Commerce Platform and Customers\n",
    "\n",
    "### 7.1 Benefits for the Platform\n",
    "- **Cost Efficiency**: Implementing an LLM-powered chatbot significantly reduces the costs associated with maintaining a large customer service team. Traditional customer service requires human agents to handle a wide range of inquiries, from simple product questions to complex order issues. Training, staffing, and managing a customer service team can be resource-intensive and expensive. By automating common customer interactions with the chatbot, the platform can reduce staffing needs and allocate human agents to higher-value tasks.\n",
    "\n",
    "  The savings are further amplified during peak shopping periods, such as holidays or sales events, when customer inquiries spike. Rather than increasing the number of support staff during these times, the chatbot can handle the influx of queries autonomously, ensuring the platform remains responsive without incurring additional labor costs.\n",
    "\n",
    "- **Scalability**: A significant advantage of using an LLM chatbot is its ability to scale effortlessly with the platform. As the customer base grows, so do the demands on customer support. Traditional customer service teams may struggle to scale without substantial investment in hiring and training new agents. In contrast, the chatbot can handle a virtually unlimited number of customer interactions simultaneously, without any degradation in performance. This scalability ensures that the platform can continue to provide a high level of service as it expands.\n",
    "\n",
    "  Furthermore, the chatbot can be continuously updated to handle new product categories, emerging customer preferences, and changes in the platform's offerings, making it adaptable to the platform's evolution without requiring extensive reprogramming.\n",
    "\n",
    "- **Data Insights**: Every interaction with the chatbot generates valuable data about customer behavior, preferences, and pain points. By analyzing these interactions, the platform can gain insights into what products are popular, what issues customers commonly face, and what improvements could enhance the user experience.\n",
    "\n",
    "  For example, if the chatbot receives a high volume of inquiries about a specific product's availability, the platform might consider adjusting inventory levels or highlighting that product more prominently on the website. Similarly, if customers frequently ask questions about certain features, the platform could improve product descriptions or provide more detailed information on the product page.\n",
    "\n",
    "  These insights can also inform broader business decisions, such as marketing strategies, product development, and customer retention initiatives. By leveraging the data generated by the chatbot, the platform can make more informed, data-driven decisions that align with customer needs and preferences.\n",
    "\n",
    "### 7.2 Benefits for Customers\n",
    "- **24/7 Availability**: One of the primary benefits of an AI chatbot for customers is the ability to receive support at any time of the day, regardless of time zones or business hours. This is particularly advantageous for global e-commerce platforms that serve customers across different regions. Customers can get instant answers to their questions, track orders, and receive product recommendations without waiting for human agents, improving the overall convenience and accessibility of the platform.\n",
    "\n",
    "  The availability of 24/7 support also enhances the shopping experience during critical moments, such as when customers are making purchasing decisions outside of regular working hours. This reduces friction in the shopping process and can lead to higher conversion rates, as customers are more likely to complete a purchase when their queries are answered promptly.\n",
    "\n",
    "- **Personalized Recommendations**: The chatbot's ability to analyze customer data, such as purchase history and browsing behavior, allows it to offer personalized product recommendations. This creates a more engaging and tailored shopping experience, as customers receive suggestions that align with their preferences and needs.\n",
    "\n",
    "  Personalized recommendations not only improve customer satisfaction but also increase the likelihood of repeat purchases. When customers feel that the platform understands their preferences, they are more likely to return for future purchases, fostering customer loyalty and retention. Additionally, personalized suggestions can help customers discover new products that they might not have otherwise considered, driving further sales.\n",
    "\n",
    "- **Fast Response Times**: Modern customers expect quick, real-time responses to their inquiries. The chatbot can deliver instant answers to common queries, such as product availability, shipping times, and order statuses, reducing the need for customers to wait for a human agent. This speed and efficiency translate into a more satisfying shopping experience, as customers can quickly find the information they need and proceed with their purchases.\n",
    "\n",
    "  The reduction in response times also minimizes frustration and improves the overall perception of the platform. By consistently providing timely and accurate information, the chatbot enhances the customer experience and encourages continued engagement with the platform.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Challenges Encountered and Solutions\n",
    "\n",
    "### 8.1 Intent Detection Limitations\n",
    "A significant challenge in implementing the chatbot was the **intent detection system**. The initial version of the chatbot relied heavily on regular expressions (regex) to detect user intent, which worked well for straightforward queries. However, regex-based systems struggle with handling complex or ambiguous inputs, such as when users ask multi-part questions or use phrasing that the chatbot has not been explicitly programmed to recognize.\n",
    "\n",
    "For instance, a user might ask, “Can you tell me the price and rating of the newest model of sneakers?” A regex-based approach may struggle to parse such a complex query accurately. Additionally, variations in how customers phrase their queries (e.g., “How much does the latest model of sneakers cost?” versus “What’s the price of the newest sneakers?”) can further complicate intent detection.\n",
    "\n",
    "To address this limitation, future iterations of the chatbot could incorporate **machine learning-based intent classifiers**, trained on a large dataset of customer interactions. These classifiers would be capable of understanding more nuanced and varied user inputs, improving the chatbot’s ability to respond accurately. By leveraging LLMs or natural language understanding (NLU) techniques, the chatbot can more effectively detect intent, regardless of the specific phrasing used by the customer.\n",
    "\n",
    "### 8.2 Handling Ambiguity and Misunderstandings\n",
    "Another challenge was the chatbot’s ability to handle ambiguous or incomplete queries. For example, if a customer asks, “What’s the price?” without specifying which product, the chatbot may struggle to generate a meaningful response. This ambiguity could lead to confusion or dissatisfaction if the chatbot repeatedly asks for clarification.\n",
    "\n",
    "To mitigate this, a **fallback mechanism** was implemented where the chatbot prompts the user for more specific information when necessary. For example, if the product name is not provided, the chatbot will ask the customer to clarify their query: “Can you please specify the product you are asking about?” This iterative refinement process helps to ensure that the chatbot can guide the conversation even when the initial query is unclear.\n",
    "\n",
    "In the future, more advanced dialogue management systems could be used to infer missing information based on the context of previous interactions. For instance, if the user recently inquired about a specific product, the chatbot could infer that the follow-up question pertains to that same product, streamlining the conversation further.\n",
    "\n",
    "### 8.3 Model Accuracy and Domain-Specific Knowledge\n",
    "LLMs like DialoGPT are trained on broad, general-purpose datasets, which makes them highly flexible but not always domain-specific. In the context of e-commerce, this generality can lead to inaccurate or irrelevant responses when dealing with highly specific questions, such as detailed product specifications or niche customer service inquiries.\n",
    "\n",
    "For example, if a customer asks for technical details about a specialized product, the chatbot might provide an answer that is too general or imprecise. To improve the chatbot’s domain-specific knowledge, it can be **fine-tuned** on a dataset composed of customer interactions, product catalogs, and support transcripts from the specific e-commerce platform. Fine-tuning allows the LLM to retain its conversational abilities while becoming more adept at handling the particularities of the e-commerce industry.\n",
    "\n",
    "Additionally, incorporating structured knowledge bases (e.g., product databases) alongside the LLM can help ensure that the chatbot provides factually accurate and up-to-date responses, particularly for product-related inquiries.\n",
    "\n",
    "### 8.4 API Rate Limits and Resource Management\n",
    "With the addition of FastAPI, another challenge was managing **API rate limits and resource allocation**. In cases where multiple users interact with the chatbot simultaneously, the server might become overloaded, impacting response times or causing service interruptions. This issue was especially relevant during peak usage times when the chatbot needed to handle numerous concurrent requests.\n",
    "\n",
    "To mitigate this, **rate-limiting mechanisms** could be implemented to control the number of requests from each user within a specified time frame. Additionally, deploying the API on a scalable cloud infrastructure (e.g., AWS or Google Cloud) with autoscaling capabilities allows for better management of fluctuating traffic. This setup ensures consistent performance by allocating resources dynamically as demand increases, helping prevent server overloads.\n",
    "\n",
    "### 8.5 Data Consistency and Synchronization\n",
    "When working with **multiple data sources** (e.g., customer, order, and product datasets), maintaining data consistency was challenging. Since the chatbot frequently queried these sources for real-time information, there was a risk of data becoming outdated or unsynchronized, especially if the datasets were modified during operation.\n",
    "\n",
    "To address this, a **caching mechanism** could be employed to temporarily store frequently accessed data, reducing the load on the database and enhancing response times. Regular synchronization processes can be scheduled to ensure that the cached data remains up-to-date with the primary datasets, reducing inconsistencies and providing users with accurate, reliable information.\n",
    "\n",
    "### 8.6 Latency in Response Times with Asynchronous Operations\n",
    "Although FastAPI supports asynchronous processing, ensuring **low latency** during high traffic periods can still be challenging, especially when the chatbot needs to query large datasets or perform complex computations. Delays may occur when the API is processing multiple requests simultaneously, resulting in slower response times.\n",
    "\n",
    "To reduce latency, **database indexing** and **efficient data retrieval techniques** were implemented to speed up queries, particularly for large tables. Additionally, using in-memory databases like Redis for caching frequently accessed data significantly improved response times. These optimizations ensure that even with asynchronous processing, the chatbot remains responsive to user queries in real-time.\n",
    "\n",
    "### 8.7 Authentication and Security\n",
    "With the public exposure of the API, **security** became a concern, particularly regarding unauthorized access and potential misuse. Although FastAPI offers several built-in security features, ensuring data privacy and securing user interactions required careful configuration.\n",
    "\n",
    "To address this, **authentication tokens** and API keys could be implemented to limit access to authorized users only. Additionally, enabling **HTTPS** would ensure encrypted communication between the client and server, protecting sensitive information during transit. These security measures help safeguard user data and prevent unauthorized access to the API.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Ethical Considerations and Privacy Implications\n",
    "\n",
    "### 9.1 Data Privacy\n",
    "The use of customer data for personalized support raises significant concerns around data privacy and security. In many regions, regulations such as the **General Data Protection Regulation (GDPR)** mandate that companies protect customer data, obtain explicit consent for its use, and ensure transparency in how the data is processed. \n",
    "\n",
    "The chatbot must adhere to these regulations by ensuring that customer data is encrypted and anonymized where possible. Additionally, the platform should provide users with clear, concise information about how their data is being used, particularly in relation to personalization features such as product recommendations. Implementing robust **data protection protocols** and **user consent mechanisms** is critical to maintaining customer trust and avoiding potential legal penalties.\n",
    "\n",
    "The platform can also allow users to opt-out of personalized recommendations or chatbot interactions involving their personal data. Providing users with control over their data not only complies with privacy laws but also fosters a sense of security and transparency.\n",
    "\n",
    "### 9.2 Bias in Recommendations\n",
    "LLMs can inadvertently reflect biases present in their training data, which can influence product recommendations or customer support interactions. For instance, if the training data disproportionately features certain product categories, the chatbot might recommend those products more frequently, even when other products may be more relevant to the customer.\n",
    "\n",
    "To mitigate bias, the chatbot’s recommendation algorithms should be **regularly audited** to ensure that they are fair and unbiased. The training data should be representative of a diverse range of products and customer preferences. Moreover, incorporating feedback loops, where customers can rate the accuracy or usefulness of recommendations, can help to identify and correct potential biases over time.\n",
    "\n",
    "### 9.3 Transparency and Consent\n",
    "It is essential that users are aware they are interacting with an AI chatbot, and that they understand how their data is being used. **Transparency** in AI interactions helps build trust between the platform and its users. The chatbot should clearly indicate that it is an AI-powered system, and it should explain its limitations (e.g., it may not always have access to the latest inventory data).\n",
    "\n",
    "Furthermore, obtaining **informed consent** is crucial, especially when using personal data for recommendations or customer service purposes. The platform should provide an easy-to-understand privacy policy, along with options for users to manage their data preferences. By being upfront about data usage and providing control to users, the platform can foster a strong, trust-based relationship with its customers.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Roadmap for Further Development and Integration into the Main E-Commerce Platform\n",
    "\n",
    "To further develop and fully integrate the LLM-based chatbot into the e-commerce platform, the following steps are outlined in a structured roadmap. This includes enhancements to the API and core functionalities to ensure seamless operation within the platform.\n",
    "\n",
    "### 1. Fine-Tuning the LLM for Domain-Specific Knowledge\n",
    "- **Action**: Fine-tune the DialoGPT model on a dataset that includes real customer interactions, product catalogs, and customer service logs from the e-commerce platform.\n",
    "- **Goal**: Improve the chatbot’s ability to handle domain-specific queries and reduce the likelihood of irrelevant or inaccurate responses.\n",
    "- **Timeline**: 2-4 weeks for data collection and model fine-tuning.\n",
    "\n",
    "### 2. Implementing a Hybrid System (LLM + Knowledge Base)\n",
    "- **Action**: Integrate a structured knowledge base that contains product information, order statuses, and FAQs. The chatbot should first attempt to query this knowledge base before falling back on the LLM.\n",
    "- **Goal**: Ensure the chatbot provides factually accurate responses, especially for critical product and order-related inquiries.\n",
    "- **Timeline**: 1-2 months to set up the knowledge base and optimize response logic.\n",
    "\n",
    "### 3. Improving Intent Detection with Machine Learning\n",
    "- **Action**: Replace the regex-based intent detection system with a machine learning-based model (e.g., using BERT or other NLU models) trained on customer queries to better detect user intent.\n",
    "- **Goal**: Enhance the chatbot's ability to handle complex, multi-part queries and varied phrasing from users.\n",
    "- **Timeline**: 3-4 weeks for model training and integration.\n",
    "\n",
    "### 4. User Feedback Integration for Continuous Improvement\n",
    "- **Action**: Implement a feedback loop where customers can rate their interactions with the chatbot. Use this feedback to fine-tune responses and improve the chatbot’s accuracy.\n",
    "- **Goal**: Continuously refine the chatbot’s performance and ensure it meets customer expectations.\n",
    "- **Timeline**: 2-3 weeks to implement and integrate feedback mechanisms.\n",
    "\n",
    "### 5. Multilingual Support\n",
    "- **Action**: Expand the chatbot’s capabilities to support multiple languages, allowing it to serve a global customer base.\n",
    "- **Goal**: Increase accessibility for non-English speaking users and improve user engagement across regions.\n",
    "- **Timeline**: 3-6 months for language model integration and testing.\n",
    "\n",
    "### 6. Integration with the E-Commerce Platform\n",
    "- **Action**: Develop APIs to connect the chatbot with the main e-commerce platform, ensuring seamless access to real-time customer data, product catalogs, and order statuses.\n",
    "- **Goal**: Fully integrate the chatbot into the platform’s existing infrastructure, enabling it to function as a primary support tool for customers.\n",
    "- **Timeline**: 1-2 months to build and test APIs.\n",
    "\n",
    "### 7. Deployment and Scalability Testing\n",
    "- **Action**: Conduct stress testing to ensure the chatbot can handle high traffic and large volumes of customer interactions, particularly during peak times (e.g., holiday sales).\n",
    "- **Goal**: Ensure the chatbot performs efficiently under high load and can scale as the customer base grows.\n",
    "- **Timeline**: 1-2 weeks for load testing and optimization.\n",
    "\n",
    "### 8. API Rate Limiting and Throttling\n",
    "- **Action**: Implement rate limiting and request throttling within the FastAPI framework to control the number of API requests from each user and prevent server overload during peak times.\n",
    "- **Goal**: Maintain high performance by managing request flow, especially under high-traffic conditions, and prevent abuse of API resources.\n",
    "- **Timeline**: 1-2 weeks for implementation and testing.\n",
    "\n",
    "### 9. Secure API Access with Authentication and Authorization\n",
    "- **Action**: Integrate authentication tokens and API keys to control access to the chatbot’s endpoints, particularly for sensitive information like customer details and order status.\n",
    "- **Goal**: Enhance security by ensuring that only authorized users can access the API, protecting customer data and sensitive platform information.\n",
    "- **Timeline**: 2-3 weeks to set up and test API security measures.\n",
    "\n",
    "### 10. Real-Time Data Synchronization for API Queries\n",
    "- **Action**: Develop a real-time data synchronization pipeline to keep the data used by the chatbot (e.g., product information, customer status) up-to-date with changes on the main e-commerce platform.\n",
    "- **Goal**: Ensure that the chatbot provides accurate and current information to users by syncing with the latest data from the platform.\n",
    "- **Timeline**: 3-4 weeks for development and integration.\n",
    "\n",
    "### 11. Enhanced API Logging and Monitoring\n",
    "- **Action**: Implement detailed logging and monitoring for API requests, tracking response times, error rates, and other performance metrics.\n",
    "- **Goal**: Improve troubleshooting and optimization by identifying bottlenecks or frequent issues in API calls, helping maintain the overall health of the system.\n",
    "- **Timeline**: 1-2 weeks for setup and configuration.\n",
    "\n",
    "### 12. Automated Testing and Quality Assurance\n",
    "- **Action**: Set up automated tests for each API endpoint, including unit tests, integration tests, and end-to-end tests, to validate functionality and performance.\n",
    "- **Goal**: Ensure the robustness and reliability of each endpoint before deployment to prevent disruptions in the chatbot’s operations.\n",
    "- **Timeline**: 2-3 weeks to develop and integrate tests.\n",
    "\n",
    "### 13. Building a Dashboard for Real-Time API Metrics and Analytics\n",
    "- **Action**: Develop an admin dashboard displaying real-time metrics, such as usage statistics, average response times, and error rates for each endpoint. This could be built using tools like Grafana or custom FastAPI dashboards.\n",
    "- **Goal**: Provide a visual overview of API performance, enabling quick insights into system health and making it easier to track improvements over time.\n",
    "- **Timeline**: 3-4 weeks for dashboard development and integration.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The implementation of an AI-powered chatbot using LLMs such as DialoGPT presents numerous advantages for e-commerce platforms, including cost efficiency, scalability, and the ability to provide personalized customer support. By leveraging the flexibility and conversational capabilities of LLMs, the chatbot can engage users in natural, context-aware conversations that enhance the shopping experience.\n",
    "\n",
    "However, challenges such as intent detection, data privacy, and bias in recommendations must be addressed to ensure the chatbot’s long-term success. Implementing solutions such as machine learning-based intent classifiers, strict data protection protocols, and regular audits for bias will be essential for optimizing the chatbot’s performance and maintaining ethical AI practices.\n",
    "\n",
    "Ultimately, the chatbot represents a powerful tool for both improving customer satisfaction and streamlining operations, helping e-commerce platforms achieve greater efficiency and build lasting relationships with their customers.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
