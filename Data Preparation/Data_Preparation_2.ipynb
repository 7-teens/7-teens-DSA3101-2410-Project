{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0g19E3luKw-5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PQUGTuhTLmzC"
      },
      "outputs": [],
      "source": [
        "customers_df = pd.read_csv('../Cleaned_Datasets/customers_sg.csv')\n",
        "products = pd.read_csv('../Cleaned_Datasets/products.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-WpZt-ItP53"
      },
      "source": [
        "# **Step 1 : Data Cleaning for products dataset**\n",
        "\n",
        "We want to clean the products dataset to make use of the products sold for synthetic data generation of our sales dataset.\n",
        "*  Removed products with total_sold == 0: Ensure that products in sales dataset are sold before\n",
        "*  Removed products with phrases 'free gift', 'not for sale', 'do not purchase', 'free gift with purchase' in their titles. This is to ensure that products used in our sales dataset are actual products purchased by customers. Based on observations,  this approach could also eliminate products with extreme pricing, as sellers often set the prices of these free gifts either excessively high or excessively low.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fPliid8Ua5TB"
      },
      "outputs": [],
      "source": [
        "# Define the list of phrases to filter out in the title column\n",
        "filter_phrases = ['do not purchase', 'free gift with purchase', 'not for sale', 'free gift', 'not for sell', 'gwp', 'gift with purchase']\n",
        "pattern = '|'.join(filter_phrases)\n",
        "\n",
        "# Filter the DataFrame to exclude rows with titles containing specified phrases and total_sold == 0\n",
        "# Filter the DataFrame to exclude rows with specified phrases in 'title', 'total_sold' equal to 0, and 'price_actual' outside the 1 to 10000 range\n",
        "products = products[\n",
        "    ~products['title'].str.contains(pattern, case=False, na=False) &\n",
        "    (products['total_sold'] != 0) &\n",
        "    (products['price_actual'] >= 1) &\n",
        "    (products['price_actual'] <= 10000)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmmKTBTaBDE1"
      },
      "source": [
        "# **Step 2 : Data preparation for customer dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFRhSfPjclB6"
      },
      "source": [
        "We create a new column in the customer dataframe to determine if the customer is a new customer or a returning customer so that we can use in our synthetic data generation for the sales dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BQEt8E6ZckPA"
      },
      "outputs": [],
      "source": [
        "# Remove duplicated customer_id entries, keeping the first occurrence\n",
        "customers_df = customers_df.drop_duplicates(subset='customer_id', keep='first').copy()\n",
        "\n",
        "# Generate a column to determine if it is new or returning customers in the customer_df\n",
        "customers_df.loc[:, 'target_audience'] = customers_df['last_checkout_day'].apply(\n",
        "    lambda x: 'new customer' if x == 'Never checkout' else 'returning customer'\n",
        ")\n",
        "\n",
        "customers_df.to_csv('customer_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaHg-Xnatozo"
      },
      "source": [
        "# **Step 3 : Preparing synthetic dataset for marketing channels**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLRwMMNEBV82"
      },
      "source": [
        "We will generate a dataset with the marketing channels information that simulates the marketing channels of Shopee. We limit our focus to the common Shopee marketing channels which are - Email, Social Media, In-App, Website, SMS and KOL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VKrdFYPDt_Tc"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "num_rows_marketing = 100000\n",
        "marketing_channels = ['Email', 'Social Media', 'In-App', 'Website', 'SMS', 'KOL']\n",
        "\n",
        "# We want to have more rows during sales period, as higher marketing spend is likely observed\n",
        "\n",
        "# Define Shopee sales dates\n",
        "mega_sales_dates = pd.to_datetime(['2019-01-01', '2019-02-02', '2019-03-03', '2019-04-04', '2019-05-05',\n",
        "                                    '2019-06-06', '2019-07-07', '2019-08-08', '2019-09-09', '2019-10-10',\n",
        "                                    '2019-11-11', '2019-12-12'])\n",
        "\n",
        "# Christmas, new year, cyber monday, black friday sales dates etc\n",
        "seasonal_sales_dates = pd.to_datetime(['2019-01-01', '2019-02-05', '2019-04-19', '2019-05-01', '2019-06-05',\n",
        "                                       '2019-06-07', '2019-08-09', '2019-08-11', '2019-10-06', '2019-10-27', '2019-11-29', '2019-12-02',\n",
        "                                       '2019-12-25', '2019-12-31'])\n",
        "\n",
        "high_sales = pd.to_datetime(['2019-11-11', '2019-12-12', '2019-11-29'])\n",
        "medium_sales = pd.to_datetime(['2019-06-06', '2019-09-09'])\n",
        "\n",
        "# Build up marketing starting 7 days before sales, with increasing priority as the sale day approaches\n",
        "days_before_sales = []\n",
        "for sale_date in high_sales:\n",
        "    days_before_sales.extend([sale_date - pd.DateOffset(days=i) for i in range(1, 8)])\n",
        "# days_before_sales = pd.DatetimeIndex(days_before_sales)\n",
        "\n",
        "mid_month_days = pd.to_datetime(['2019-' + str(month).zfill(2) + '-15' for month in range(1, 13)] +\n",
        "                                ['2019-' + str(month).zfill(2) + '-25' for month in range(1, 13)])\n",
        "\n",
        "\n",
        "dates = pd.date_range(start='2019-01-01', end='2019-12-31', freq='D').to_list()\n",
        "\n",
        "# Base probabilities (low for regular dates)\n",
        "base_prob = 1 / len(dates)\n",
        "probabilities = np.full(len(dates), base_prob)\n",
        "\n",
        "# Adjust probabilities for sale days and periods\n",
        "for i, date in enumerate(dates):\n",
        "    if date in high_sales:\n",
        "        # Higher priority for sales dates but slightly lower than pre-sale days\n",
        "        probabilities[i] = 0.04\n",
        "    elif date in days_before_sales:\n",
        "        # Pre-sale marketing build-up for high-priority sales (1-7 days before)\n",
        "        days_diff = (high_sales - date).days.min()\n",
        "        if days_diff == 1:\n",
        "            probabilities[i] = 0.06\n",
        "        elif days_diff in [2, 3]:\n",
        "            probabilities[i] = 0.04\n",
        "        elif days_diff in [4, 5]:\n",
        "            probabilities[i] = 0.03\n",
        "        elif days_diff in [6, 7]:\n",
        "            probabilities[i] = 0.015\n",
        "    elif date in mid_month_days:\n",
        "        probabilities[i] = 0.015\n",
        "    elif date in seasonal_sales_dates:\n",
        "        probabilities[i] = 0.05\n",
        "    else:\n",
        "        probabilities[i] = base_prob\n",
        "\n",
        "# Normalize probabilities\n",
        "probabilities /= probabilities.sum()\n",
        "marketing_dates = np.random.choice(dates, size=num_rows_marketing, p=probabilities)\n",
        "\n",
        "# Given Shopee spent an estimated US$500 million on marketing spend in SEA\n",
        "total_shopee_spend = 500000000\n",
        "sg_share = 0.04\n",
        "sg_shopee_spend = total_shopee_spend * sg_share\n",
        "\n",
        "# Simulate Shopee's marketing channel proportions\n",
        "channel_proportions = {\n",
        "    'Email': 0.12,\n",
        "    'Social Media': 0.22,\n",
        "    'In-App': 0.24,\n",
        "    'KOL': 0.20,\n",
        "    'Website': 0.17,\n",
        "    'SMS': 0.05,\n",
        "}\n",
        "\n",
        "# We calculate total expenditure per channel based on proportions\n",
        "total_expenditures = {channel: sg_shopee_spend * proportion for channel, proportion in channel_proportions.items()}\n",
        "\n",
        "# Simulate for pre-sale days - higher for social media and KOL as these channels are likely to have more marketing pre-sale\n",
        "pre_sale_channel_weights = {\n",
        "    'Email': 0.08,\n",
        "    'Social Media': 0.35,\n",
        "    'In-App': 0.15,\n",
        "    'Website': 0.12,\n",
        "    'SMS': 0.05,\n",
        "    'KOL': 0.25\n",
        "}\n",
        "\n",
        "# Simulate for sale days - higher for in-app\n",
        "sale_day_channel_weights = {\n",
        "    'Email': 0.07,\n",
        "    'Social Media': 0.20,\n",
        "    'In-App': 0.35,\n",
        "    'Website': 0.15,\n",
        "    'SMS': 0.05,\n",
        "    'KOL': 0.18\n",
        "}\n",
        "\n",
        "channels = []\n",
        "for date in marketing_dates:\n",
        "    if date in high_sales:\n",
        "        channel_weights = list(sale_day_channel_weights.values())\n",
        "        chosen_channel = np.random.choice(marketing_channels, p=channel_weights)\n",
        "    elif date in days_before_sales:\n",
        "        channel_weights = list(pre_sale_channel_weights.values())\n",
        "        chosen_channel = np.random.choice(marketing_channels, p=channel_weights)\n",
        "    else:\n",
        "        channel_weights = list(channel_proportions.values())\n",
        "        chosen_channel = np.random.choice(marketing_channels, p=channel_weights)\n",
        "    channels.append(chosen_channel)\n",
        "\n",
        "channels\n",
        "\n",
        "marketing_df = pd.DataFrame({'channel_name': channels})\n",
        "\n",
        "# We want to calculate the total expenditure per channel\n",
        "channel_counts = marketing_df['channel_name'].value_counts().to_dict()\n",
        "\n",
        "# We want to spread out the expenditure per channel and add in some random variation for realism\n",
        "def spread_expenditure(channel_name):\n",
        "    if channel_name in channel_counts:\n",
        "        current_expenditure = total_expenditures[channel_name] / channel_counts[channel_name]\n",
        "        random_variation = np.random.uniform(-0.2, 0.2)  # Variation between -20% and +20%\n",
        "        return round(current_expenditure * (1 + random_variation), 2)\n",
        "    return 0\n",
        "\n",
        "marketing_df['channel_expenditure'] = marketing_df['channel_name'].apply(spread_expenditure)\n",
        "\n",
        "visitor_multipliers = {\n",
        "    'Email': np.random.uniform(2, 4),\n",
        "    'SMS': np.random.uniform(1.5, 3),\n",
        "    'KOL': np.random.uniform(2, 6),\n",
        "    'In-App': np.random.uniform(2, 5.5),\n",
        "    'Social Media': np.random.uniform(1.2, 7),\n",
        "    'Website': np.random.uniform(2, 4.2)\n",
        "}\n",
        "\n",
        "visitors = [\n",
        "    np.round(marketing_df['channel_expenditure'][i] * visitor_multipliers[channels[i]], 0)\n",
        "    for i in range(num_rows_marketing)\n",
        "]\n",
        "\n",
        "conversion_rates = {\n",
        "    'Email': np.random.uniform(0.025, 0.04),\n",
        "    'SMS': np.random.uniform(0.03, 0.035),\n",
        "    'KOL': np.random.uniform(0.05, 0.08),\n",
        "    'In-App': np.random.uniform(0.03, 0.06),\n",
        "    'Social Media': np.random.uniform(0.02, 0.05),\n",
        "    'Website': np.random.uniform(0.02, 0.04)\n",
        "}\n",
        "\n",
        "conversion_rate_list = np.array([\n",
        "    conversion_rates[channels[i]] for i in range(num_rows_marketing)\n",
        "])\n",
        "\n",
        "# Calculate sales generated based on visitors and conversion rates\n",
        "sales_generated = np.round(visitors * conversion_rate_list, 0)\n",
        "sales_generated = np.where(sales_generated == 0, 1, sales_generated)\n",
        "conversion_rate_calc = (sales_generated / visitors) * 100\n",
        "\n",
        "# Average Order Value - overall for Shopee is around $15-$25\n",
        "aov_list = [\n",
        "    np.random.uniform(8, 25) if channel == 'Email' else\n",
        "    np.random.uniform(6, 10) if channel == 'SMS' else\n",
        "    np.random.uniform(15, 30) if channel == 'KOL' else\n",
        "    np.random.uniform(10, 22) if channel == 'In-App' else\n",
        "    np.random.uniform(10, 16) if channel == 'Social Media' else\n",
        "    np.random.uniform(8, 20)\n",
        "    for channel in channels\n",
        "]\n",
        "\n",
        "# Calculate Total Revenue based on sales and AOV, but ensure that revenue is > expenditure for realism\n",
        "total_revenue = []\n",
        "\n",
        "for i in range(num_rows_marketing):\n",
        "    expenditure = marketing_df['channel_expenditure'].iloc[i]\n",
        "    revenue = sales_generated[i] * aov_list[i]\n",
        "    if revenue <= expenditure:\n",
        "        revenue = expenditure * np.random.uniform(1.1, 1.3)\n",
        "\n",
        "    total_revenue.append(round(revenue, 2))\n",
        "\n",
        "# We want to simulate the CTR for each marketing channel based on average E-commerce CTR scenarios\n",
        "click_through_rate = [\n",
        "    np.random.uniform(0.02, 0.03) if channel == 'Email' else  # 2% to 3%\n",
        "    np.random.uniform(0.01, 0.02) if channel == 'SMS' else    # 1% to 2%\n",
        "    np.random.uniform(0.02, 0.04) if channel == 'KOL' else    # 2% to 4%\n",
        "    np.random.uniform(0.005, 0.015) if channel == 'In-App' else  # 0.5% to 1.5%\n",
        "    np.random.uniform(0.01, 0.04) if channel == 'Social Media' else  # 1% to 4%\n",
        "    np.random.uniform(0.005, 0.01)  # 0.5% to 1% for Website Ads\n",
        "    for channel in channels\n",
        "]\n",
        "\n",
        "# We want to simulate the Bounce rates for each marketing channel based on average E-commerce bounce rates scenarios\n",
        "bounce_rate = [\n",
        "    np.random.uniform(30, 40) if channel == 'Email' else       # 30-40%\n",
        "    np.random.uniform(40, 50) if channel == 'SMS' else         # 40-50%\n",
        "    np.random.uniform(35, 45) if channel == 'KOL' else         # 35-45%\n",
        "    np.random.uniform(50, 60) if channel == 'In-App' else      # 50-60%\n",
        "    np.random.uniform(50, 60) if channel == 'Social Media' else # 50-60%\n",
        "    np.random.uniform(55, 65)  # 55-65% for Website ads\n",
        "    for channel in channels\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tfiDW6z5Uk7",
        "outputId": "d31fe51e-692b-4e4e-e0c9-05fa53879785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        date  channel_name  channel_expenditure  channel_visitors  \\\n",
            "0 2019-06-07       Website               165.48             444.0   \n",
            "1 2019-12-15        In-App               201.15             736.0   \n",
            "2 2019-11-06  Social Media               157.74             999.0   \n",
            "3 2019-09-18        In-App               200.18             732.0   \n",
            "4 2019-03-13        In-App               180.24             659.0   \n",
            "\n",
            "   channel_sales  conversion_rate  average_order_value  total_revenue  \\\n",
            "0           14.0         3.153153            16.701049         233.81   \n",
            "1           30.0         4.076087            19.295899         578.88   \n",
            "2           40.0         4.004004            11.439214         457.57   \n",
            "3           29.0         3.961749            16.086238         466.50   \n",
            "4           26.0         3.945372            16.697335         434.13   \n",
            "\n",
            "   click_through_rate  bounce_rate  \n",
            "0            0.009033    62.637806  \n",
            "1            0.008315    55.581256  \n",
            "2            0.017502    55.664460  \n",
            "3            0.012964    55.497740  \n",
            "4            0.007800    59.281288  \n"
          ]
        }
      ],
      "source": [
        "# Now we join the above columns to create our synthetic dataframe\n",
        "marketing_df = pd.DataFrame({\n",
        "    'date': marketing_dates,\n",
        "    'channel_name': channels,\n",
        "    'channel_expenditure': marketing_df['channel_expenditure'],\n",
        "    'channel_visitors': visitors,\n",
        "    'channel_sales': sales_generated,\n",
        "    'conversion_rate': conversion_rate_calc,\n",
        "    'average_order_value': aov_list,\n",
        "    'total_revenue': total_revenue,\n",
        "    'click_through_rate': click_through_rate,\n",
        "    'bounce_rate': bounce_rate,\n",
        "    #'customer_retention_rate': customer_retention_rate\n",
        "})\n",
        "\n",
        "print(marketing_df.head())\n",
        "marketing_df['day'] = marketing_df['date'].dt.day_name()\n",
        "marketing_df.to_csv('synthetic_marketing_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QRfIJpbudq3"
      },
      "source": [
        "# **Step 4 : Preparing synthetic dataset for promotional campaigns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaQFj8EBVX-3",
        "outputId": "b0b3489a-f3fc-4f90-ff28-f4c2a1283623"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-ab304a92d530>:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  campaign_df['target_audience'].fillna('new customer', inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of        campaign_id         campaign_type  campaign_cost  session_id  \\\n",
            "0          7423388     Next Day Delivery           2035       66967   \n",
            "1          7550634            Flash Sale           9823      855986   \n",
            "2          5304572            Mega Sales           9023      305478   \n",
            "3          3234489     Bundle promotions           1448      428910   \n",
            "4          8204212            Mega Sales           1520      993376   \n",
            "...            ...                   ...            ...         ...   \n",
            "99995      3965488            Mega Sales           6286      345093   \n",
            "99996      5569161            Mega Sales           9400      771967   \n",
            "99997      3412534     Next Day Delivery           5345      883913   \n",
            "99998      4864695            Mega Sales           1427      196137   \n",
            "99999      2692728  Livestream Exclusive           5375      969209   \n",
            "\n",
            "      start_date   end_date marketing_channel promotional_discount_type  \\\n",
            "0     2019-01-12 2019-01-15               KOL                Percentage   \n",
            "1     2019-09-16 2019-09-19            In-App              Fixed Amount   \n",
            "2     2019-10-09 2019-10-11      Social Media              Fixed Amount   \n",
            "3     2019-05-11 2019-05-14      Social Media              Fixed Amount   \n",
            "4     2019-04-03 2019-04-05            In-App              Fixed Amount   \n",
            "...          ...        ...               ...                       ...   \n",
            "99995 2019-03-02 2019-03-04      Social Media              Fixed Amount   \n",
            "99996 2019-11-10 2019-11-12      Social Media                Percentage   \n",
            "99997 2019-11-20 2019-11-23               KOL                Percentage   \n",
            "99998 2019-11-10 2019-11-12      Social Media                Percentage   \n",
            "99999 2019-01-22 2019-01-25      Social Media              Fixed Amount   \n",
            "\n",
            "       promotional_discount_value  gender    age_group  is_click  customer_id  \\\n",
            "0                            29.0  Female  18-24 years         0       108480   \n",
            "1                            15.0    Male  18-24 years         0       121526   \n",
            "2                            16.0  Female  35-44 years         0        85601   \n",
            "3                             4.0  Female  25-34 years         0        95857   \n",
            "4                             5.0  Female  35-44 years         0        40919   \n",
            "...                           ...     ...          ...       ...          ...   \n",
            "99995                        16.0    Male  55-64 years         0        85711   \n",
            "99996                        30.0  Female  35-44 years         0        55668   \n",
            "99997                        39.0    Male  45-54 years         0        20128   \n",
            "99998                        56.0  Female  55-64 years         0        21768   \n",
            "99999                         3.0  Female  35-44 years         0        62540   \n",
            "\n",
            "          target_audience  \n",
            "0      returning customer  \n",
            "1      returning customer  \n",
            "2      returning customer  \n",
            "3      returning customer  \n",
            "4      returning customer  \n",
            "...                   ...  \n",
            "99995  returning customer  \n",
            "99996  returning customer  \n",
            "99997  returning customer  \n",
            "99998  returning customer  \n",
            "99999  returning customer  \n",
            "\n",
            "[100000 rows x 14 columns]>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "num_rows = 100000\n",
        "\n",
        "# Campaign Type Dataset\n",
        "campaign_ids = [np.random.randint(1000000, 9999999) for _ in range(num_rows)]\n",
        "campaign_types = ['Flash Sale', 'Seasonal Sales', 'Bundle promotions', 'Mega Sales', 'Livestream Exclusive', 'Next Day Delivery']\n",
        "campaign_costs = np.random.randint(1000, 10000, size=num_rows)\n",
        "\n",
        "# Unique session ids\n",
        "unique_session_ids = np.random.choice(range(1, 999999), size=num_rows, replace=False)\n",
        "session_ids = np.random.choice(unique_session_ids, size=num_rows, replace=False)\n",
        "\n",
        "# Generate customer ids based on customer_id in the customer_df\n",
        "customer_ids = np.random.choice(customers_df['customer_id'], size=num_rows, replace=True)\n",
        "\n",
        "# Generate gender & age columns for the customer\n",
        "gender = np.random.choice(['Male', 'Female'], size=num_rows)\n",
        "years = ['0-17 years', '18-24 years', '25-34 years', '35-44 years', '45-54 years', '55-64 years', '65 years and older']\n",
        "age_group_probabilities = [0.04, 0.20, 0.33, 0.25, 0.12, 0.06, 0.00]  #increase probability for '25-34 years'\n",
        "age_group = np.random.choice(years, size=num_rows, p=age_group_probabilities)\n",
        "\n",
        "# CTR\n",
        "marketing_channel_probabilities = {\n",
        "    'In-App': [0.2, 0.80],\n",
        "    'Social Media': [0.1, 0.9],\n",
        "    'KOL': [0.08, 0.92],\n",
        "    'Email': [0.05, 0.95],\n",
        "    'Website': [0.05, 0.95],\n",
        "    'SMS': [0.02, 0.98]\n",
        "}\n",
        "\n",
        "# Simulate campaign data with marketing channels\n",
        "channels = np.random.choice(list(marketing_channel_probabilities.keys()), size=num_rows)\n",
        "\n",
        "# Generate is_click based on the probabilities for each channel\n",
        "is_click = []\n",
        "for channel in channels:\n",
        "    click_prob = marketing_channel_probabilities[channel]\n",
        "    is_click.append(np.random.choice([1, 0], p=click_prob))\n",
        "\n",
        "# Convert to a NumPy array\n",
        "is_click = np.array(is_click)\n",
        "\n",
        "# Define key dates for Mega Sales and Seasonal Sales, increasing priority for 2019-11-11\n",
        "mega_sales_dates = pd.to_datetime(['2019-01-01', '2019-02-02', '2019-03-03', '2019-04-04', '2019-05-05',\n",
        "                                   '2019-06-06', '2019-07-07', '2019-08-08', '2019-09-09', '2019-10-10',\n",
        "                                   '2019-11-11', '2019-12-12'])\n",
        "\n",
        "seasonal_sales_dates = pd.to_datetime(['2019-01-01', '2019-02-05', '2019-04-19', '2019-05-01', '2019-06-05',\n",
        "                                       '2019-06-07', '2019-08-09', '2019-08-11', '2019-10-06', '2019-10-27', '2019-11-29', '2019-12-02',\n",
        "                                       '2019-12-25', '2019-12-31'])\n",
        "\n",
        "# Initialize lists for start and end dates\n",
        "start_dates = []\n",
        "end_dates = []\n",
        "campaign_type_choices = []\n",
        "\n",
        "# Define available dates excluding mega_sales_dates and seasonal_sales_dates\n",
        "excluded_dates = list(mega_sales_dates) + list(seasonal_sales_dates)\n",
        "available_dates = pd.date_range('2019-01-01', '2019-12-31', freq='D').difference(excluded_dates)\n",
        "\n",
        "# Adjust the loop to select from available_dates for non-special campaigns\n",
        "for _ in range(num_rows):\n",
        "    campaign_type = np.random.choice(campaign_types, p=[0.1, 0.1, 0.1, 0.4, 0.15, 0.15])  # Higher probability for Mega Sales\n",
        "    campaign_type_choices.append(campaign_type)\n",
        "\n",
        "    if campaign_type == 'Mega Sales':\n",
        "        if np.random.rand() < 0.5:\n",
        "            date = pd.Timestamp('2019-11-11')\n",
        "        else:\n",
        "            date = np.random.choice(mega_sales_dates)\n",
        "        start_dates.append(date - pd.Timedelta(days=1))\n",
        "        end_dates.append(date + pd.Timedelta(days=1))\n",
        "    elif campaign_type == 'Seasonal Sales':\n",
        "        index = np.random.randint(len(seasonal_sales_dates))\n",
        "        start_dates.append(seasonal_sales_dates[index] - pd.Timedelta(days=1))\n",
        "        end_dates.append(seasonal_sales_dates[index] + pd.Timedelta(days=1))\n",
        "    else:\n",
        "        # Select a random date from available_dates for other campaign types\n",
        "        random_start = pd.Timestamp(np.random.choice(available_dates))\n",
        "        start_dates.append(random_start)\n",
        "        end_dates.append(random_start + pd.Timedelta(days=3)) # 3 days campaign\n",
        "\n",
        "# Marketing channel, target audience, promotional type, and discount columns\n",
        "marketing_channels = ['In-App', 'Social Media', 'KOL', 'Email', 'Website', 'SMS']\n",
        "marketing_channel_prob = [0.4, 0.3, 0.2, 0.03, 0.05, 0.02]  # Higher probabilities for In-App, Social Media, and KOL\n",
        "\n",
        "promotional_discount_types = np.random.choice(['Percentage', 'Fixed Amount'], size=num_rows)\n",
        "promotional_discount_values = np.zeros(num_rows)\n",
        "\n",
        "promotional_discount_values[promotional_discount_types == 'Percentage'] = np.random.randint(20, 61, size=(promotional_discount_types == 'Percentage').sum())\n",
        "promotional_discount_values[promotional_discount_types == 'Fixed Amount'] = np.random.randint(2, 21, size=(promotional_discount_types == 'Fixed Amount').sum())\n",
        "\n",
        "campaign_df = pd.DataFrame({\n",
        "    'campaign_id': campaign_ids,\n",
        "    'campaign_type': campaign_type_choices,\n",
        "    'campaign_cost': campaign_costs,\n",
        "    'session_id': session_ids,\n",
        "    'start_date': start_dates,\n",
        "    'end_date': end_dates,\n",
        "    'marketing_channel': np.random.choice(marketing_channels, size=num_rows, p=marketing_channel_prob),\n",
        "    'promotional_discount_type': promotional_discount_types,\n",
        "    'promotional_discount_value': promotional_discount_values,\n",
        "    'gender': gender,\n",
        "    'age_group': age_group,\n",
        "    'is_click': is_click,\n",
        "    'customer_id': customer_ids\n",
        "})\n",
        "\n",
        "# Merge to get target_audience column\n",
        "campaign_df = campaign_df.merge(customers_df[['customer_id', 'target_audience']], on='customer_id', how='left')\n",
        "campaign_df['target_audience'].fillna('new customer', inplace=True)\n",
        "\n",
        "\n",
        "print(campaign_df.head)\n",
        "# Save the campaign DataFrame to CSV\n",
        "campaign_df.to_csv('synthetic_campaign_data.csv', index=False)\n",
        "len(campaign_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-r9vWr-uzSU"
      },
      "source": [
        "# **Step 5 : Preparing synthetic order & sales dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_mnebBxe4VR",
        "outputId": "0f08f539-d732-45cd-d3c8-5f7a7fe35f3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['order_id', 'product_id', 'session_id', 'is_campaign', 'campaign',\n",
            "       'main_category', 'price', 'total_sold', 'title', 'Stock', 'customer_id',\n",
            "       'promotional_discount_type', 'gender', 'price_range', 'order_time',\n",
            "       'discount'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "num_rows = 100000\n",
        "\n",
        "# Shopee Sales Dataset\n",
        "target_categories = ['Home & Living', 'Health & Beauty', 'Mobile & Accessories']\n",
        "category_sales_prob = products['main_category'].value_counts(normalize=True)\n",
        "category_sales_prob.update(category_sales_prob[target_categories] * 2)\n",
        "category_sales_prob = category_sales_prob / category_sales_prob.sum()\n",
        "product_category_prob = products['main_category'].map(category_sales_prob)\n",
        "product_category_prob = product_category_prob / product_category_prob.sum()\n",
        "\n",
        "order_id = [np.random.randint(100000, 10000000) for _ in range(num_rows)]\n",
        "unique_session_ids = campaign_df['session_id'].unique()\n",
        "np.random.shuffle(unique_session_ids)\n",
        "extended_session_ids = unique_session_ids[:100000]\n",
        "\n",
        "\n",
        "duplicated_product_ids = np.random.choice(products['product_id'], size=num_rows, replace=True, p=product_category_prob)\n",
        "duplicated_customer_ids = np.random.choice(campaign_df['customer_id'], size=num_rows, replace=True)\n",
        "all_campaign_types = campaign_df['campaign_type'].unique().tolist() + ['Regular day']\n",
        "\n",
        "# Define probabilities for each campaign type, including 'Regular day'\n",
        "probabilities = [0.075, 0.075, 0.075, 0.4, 0.15, 0.15, 0.075]  # Ensure this matches the number of campaign types\n",
        "\n",
        "duplicated_campaign_types = np.random.choice(all_campaign_types, size=num_rows, p=probabilities)# Set is_campaign based on the campaign type\n",
        "is_campaign = np.where(duplicated_campaign_types == 'Regular day', 0, 1)\n",
        "\n",
        "campaign_data = pd.DataFrame({\n",
        "    'campaign_type': duplicated_campaign_types,\n",
        "    'is_campaign': is_campaign\n",
        "})\n",
        "\n",
        "product_df = products[['product_id', 'main_category', 'price_actual', 'total_sold', 'title', 'Stock']].rename(columns={'price_actual': 'price'})\n",
        "\n",
        "orders = pd.DataFrame({\n",
        "    'order_id': order_id,\n",
        "    'product_id': duplicated_product_ids,\n",
        "    'session_id': extended_session_ids,\n",
        "    'is_campaign': is_campaign,\n",
        "    'campaign': duplicated_campaign_types\n",
        "})\n",
        "\n",
        "# Merge with product_df (product information)\n",
        "orders = orders.merge(product_df, on='product_id', how='left')\n",
        "\n",
        "# Merge with campaign_df (campaign information)\n",
        "orders = orders.merge(campaign_df[['session_id','customer_id', 'campaign_type', 'promotional_discount_type', 'gender']], on='session_id', how='left')\n",
        "orders['campaign'] = orders['campaign_type']\n",
        "orders.drop(columns=['campaign_type'], inplace=True)\n",
        "\n",
        "# Defining Price Bins and Labels\n",
        "price_bins = [0, 20, 50, 100, 500, float('inf')]\n",
        "price_labels = ['Low', 'Mid-Low', 'Mid', 'Mid-High', 'High']\n",
        "orders['price_range'] = pd.cut(orders['price'], bins=price_bins, labels=price_labels)\n",
        "\n",
        "\n",
        "high_priority_mega_sales_dates = ['2019-11-11', '2019-09-09', '2019-10-10', '2019-12-12']\n",
        "additional_mega_sales_dates = [\n",
        "    '2019-01-01', '2019-02-02', '2019-03-03', '2019-04-04', '2019-05-05',\n",
        "    '2019-06-06', '2019-07-07', '2019-08-08'\n",
        "]\n",
        "other_seasonal_sales_dates = ['2019-01-01', '2019-02-05', '2019-04-19', '2019-05-01', '2019-06-05',\n",
        "                                       '2019-06-07', '2019-08-09', '2019-08-11', '2019-10-06', '2019-10-27', '2019-12-02',\n",
        "                                       '2019-12-25', '2019-12-31']\n",
        "\n",
        "# Higher Sales on Black Friday\n",
        "high_priority_seasonal_sales_dates = ['2019-11-29']\n",
        "early_december_dates = pd.date_range('2019-12-01', '2019-12-24').to_list()\n",
        "\n",
        "mega_sales_dates = pd.to_datetime(high_priority_mega_sales_dates + additional_mega_sales_dates)\n",
        "seasonal_sales_dates = pd.to_datetime(high_priority_seasonal_sales_dates + early_december_dates)\n",
        "\n",
        "exclude = list(mega_sales_dates) + list(seasonal_sales_dates)\n",
        "regular_dates = pd.date_range('2019-01-01', '2019-12-31', freq='D').difference(exclude)\n",
        "\n",
        "mega_priority_probs = [0.5 if date == '2019-11-11' else 0.2 if date in ['2019-09-09', '2019-10-10', '2019-12-12'] else 0.01 for date in mega_sales_dates]\n",
        "seasonal_priority_probs = [0.3 if date == '2019-11-29' else 0.02 if date in other_seasonal_sales_dates else 0.4 / len(early_december_dates) for date in seasonal_sales_dates]\n",
        "total_mega_prob = sum(mega_priority_probs)\n",
        "mega_priority_probs = [p / total_mega_prob * 0.8 for p in mega_priority_probs]\n",
        "\n",
        "total_seasonal_prob = sum(seasonal_priority_probs)\n",
        "seasonal_priority_probs = [p / total_seasonal_prob * 0.2 for p in seasonal_priority_probs]\n",
        "\n",
        "all_dates = list(mega_sales_dates) + list(seasonal_sales_dates) + list(regular_dates)\n",
        "combined_probs = mega_priority_probs + seasonal_priority_probs + [0.01 / len(regular_dates)] * len(regular_dates)  # Small probability for regular dates\n",
        "\n",
        "# Ensure probabilities sum to 1\n",
        "combined_probs = np.array(combined_probs) / sum(combined_probs)\n",
        "\n",
        "order_times = np.random.choice(all_dates, size=num_rows, p=combined_probs)\n",
        "# Assign generated order times to the 'order_time' column in the 'orders' DataFrame\n",
        "orders['order_time'] = order_times\n",
        "\n",
        "orders['discount'] = 0\n",
        "\n",
        "# Apply discounts for 'Percentage' type based on campaign type and order time\n",
        "percentage_discount_conditions = (\n",
        "    (orders['promotional_discount_type'] == 'Percentage') &\n",
        "    (orders['is_campaign'] == 1)\n",
        ")\n",
        "\n",
        "for i in range(len(orders)):\n",
        "    # Check if the row meets the percentage discount conditions\n",
        "    if percentage_discount_conditions[i]:\n",
        "\n",
        "        # Apply discount based on specific campaign conditions\n",
        "        if orders.loc[i, 'order_time'] == '2019-11-11' and orders.loc[i, 'campaign'] == 'Mega Sales':\n",
        "            orders.loc[i, 'discount'] = np.random.randint(20, 51)\n",
        "\n",
        "        elif orders.loc[i, 'campaign'] == 'Flash Sale':\n",
        "            orders.loc[i, 'discount'] = np.random.randint(15, 31)\n",
        "\n",
        "        elif orders.loc[i, 'campaign'] == 'Seasonal Sales':\n",
        "            orders.loc[i, 'discount'] = np.random.randint(20, 41)\n",
        "\n",
        "        elif orders.loc[i, 'campaign'] == 'Bundle promotions':\n",
        "            orders.loc[i, 'discount'] = np.random.randint(5, 16)\n",
        "\n",
        "        elif orders.loc[i, 'campaign'] == 'Livestream Exclusive':\n",
        "            orders.loc[i, 'discount'] = np.random.randint(25, 41)\n",
        "\n",
        "        elif orders.loc[i, 'campaign'] == 'Next Day Delivery':\n",
        "            orders.loc[i, 'discount'] = np.random.randint(0, 11)\n",
        "        else:\n",
        "            orders.loc[i, 'discount'] = 0\n",
        "    else:\n",
        "        # Set discount to 0 if no percentage discount condition is met\n",
        "        orders.loc[i, 'discount'] = 0\n",
        "\n",
        "\n",
        "\n",
        "# Apply discounts for 'Fixed Amount' type, ensuring discount is less than the product price\n",
        "fixed_amount_discount_conditions = (\n",
        "    (orders['promotional_discount_type'] == 'Fixed Amount') &\n",
        "    (orders['is_campaign'] == 1)\n",
        ")\n",
        "\n",
        "# Generate discount values for Fixed Amount and ensure they do not exceed the product price\n",
        "for idx in orders[fixed_amount_discount_conditions].index:\n",
        "    max_discount = max(1, orders.loc[idx, 'price'] - 1)  # Ensure a minimum of 1 and max less than price\n",
        "    orders.loc[idx, 'discount'] = np.random.randint(1, max_discount + 1)\n",
        "\n",
        "print(orders.columns)\n",
        "\n",
        "# Save the orders DataFrame to CSV\n",
        "orders.to_csv('shopee_sales_df.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
